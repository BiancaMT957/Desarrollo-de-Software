## 1. Definici√≥n de IaC y su cambio de paradigma frente a la configuraci√≥n manual

Infraestructura como C√≥digo (IaC) es un enfoque que permite gestionar la infraestructura mediante archivos de configuraci√≥n en lugar de realizar configuraciones manuales a trav√©s de interfaces gr√°ficas o herramientas de administraci√≥n tradicionales. Este enfoque describe el estado deseado de la infraestructura utilizando un lenguaje declarativo o imperativo, lo que facilita la creaci√≥n, modificaci√≥n y administraci√≥n de recursos de manera autom√°tica.

### Cambio de paradigma

La diferencia principal entre IaC y la configuraci√≥n manual es que en IaC la infraestructura se gestiona como c√≥digo, permitiendo la automatizaci√≥n completa del ciclo de vida de los recursos. Esto no solo mejora la eficiencia, sino que reduce significativamente los errores humanos, ya que las configuraciones y cambios se pueden revisar, versionar y auditar a trav√©s de herramientas de control de versiones como Git.

---

## 2. Beneficios de IaC

- **Consistencia en la configuraci√≥n**: La infraestructura definida como c√≥digo puede aplicarse de manera consistente en diferentes entornos (desarrollo, prueba, producci√≥n) sin la posibilidad de diferencias manuales.
- **Control de versiones**: Los archivos de configuraci√≥n son versionados, lo que permite hacer un seguimiento de los cambios, revertir configuraciones err√≥neas y mantener un historial completo de la infraestructura.
- **Automatizaci√≥n**: La infraestructura se aprovisiona, configura y gestiona autom√°ticamente sin intervenci√≥n manual. Esto optimiza el tiempo y esfuerzo de los equipos de TI.
- **Reducci√≥n de errores humanos**: Al evitar configuraciones manuales, el riesgo de cometer errores en el proceso de configuraci√≥n se reduce considerablemente, ya que todo el proceso est√° automatizado y auditado.

---

## 3. Herramientas populares para IaC

Algunas de las herramientas m√°s populares para implementar IaC son:

- **Terraform**: Usada ampliamente en m√∫ltiples proveedores de nube como AWS, Azure y Google Cloud. Utiliza el HashiCorp Configuration Language (HCL) para definir y gestionar la infraestructura.
- **Ansible**: Aunque es m√°s conocida por la automatizaci√≥n de configuraciones y aplicaciones, Ansible tambi√©n permite definir la infraestructura como c√≥digo. Utiliza YAML para describir las tareas a realizar.
- **Pulumi**: Permite escribir IaC utilizando lenguajes de programaci√≥n modernos como JavaScript, TypeScript, Python y Go.
- **AWS CloudFormation**: Espec√≠fica para AWS, permite definir recursos de infraestructura en la nube utilizando archivos en JSON o YAML.

---

## 4. Buenas pr√°cticas en la escritura de IaC

- **Nombres claros de recursos**: Utilizar nombres descriptivos y consistentes para los recursos ayuda a identificar r√°pidamente su prop√≥sito y facilita la gesti√≥n en entornos grandes.
- **Uso de variables**: Las variables permiten reutilizar configuraciones de manera eficiente y hacer que los recursos sean m√°s din√°micos y personalizables seg√∫n el entorno.
- **Modularizaci√≥n del c√≥digo**: Es recomendable dividir la infraestructura en m√≥dulos que se puedan reutilizar en diferentes proyectos o entornos. Por ejemplo, un m√≥dulo para redes, otro para bases de datos y otro para aplicaciones.
- **Uso de repositorios de control de versiones (Git)**: Mantener el c√≥digo de la infraestructura en un repositorio Git permite un control completo sobre los cambios, adem√°s de colaborar y hacer auditor√≠a sobre las configuraciones.

---

## 5. Patrones para m√≥dulos en IaC

### Modularizaci√≥n

Separar los recursos en m√≥dulos l√≥gicos facilita la reutilizaci√≥n y la gesti√≥n. Por ejemplo, un m√≥dulo para configurar redes, otro para definir bases de datos y otro para gestionar servidores de aplicaciones. Cada m√≥dulo puede ser independiente y gestionado de manera aislada, permitiendo su reutilizaci√≥n en diferentes proyectos.

### Estructura

Una estructura de m√≥dulos t√≠pica en IaC podr√≠a organizarse de la siguiente manera:

```
‚îú‚îÄ‚îÄ modules/
‚îÇ   ‚îú‚îÄ‚îÄ network/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.tf
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ variables.tf
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ outputs.tf
‚îÇ   ‚îú‚îÄ‚îÄ database/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.tf
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ variables.tf
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ outputs.tf
‚îÇ   ‚îî‚îÄ‚îÄ application/
‚îÇ       ‚îú‚îÄ‚îÄ main.tf
‚îÇ       ‚îú‚îÄ‚îÄ variables.tf
‚îÇ       ‚îî‚îÄ‚îÄ outputs.tf
‚îú‚îÄ‚îÄ main.tf
‚îú‚îÄ‚îÄ variables.tf
‚îî‚îÄ‚îÄ outputs.tf
```

Aqu√≠, cada m√≥dulo tiene su propio conjunto de archivos que describen los recursos y las configuraciones, y luego los m√≥dulos se llaman en el archivo `main.tf` del proyecto principal.

---

## 6. Patrones para dependencias en IaC

### Gesti√≥n de dependencias

Para enlazar m√≥dulos que dependen entre s√≠, como un m√≥dulo de base de datos que debe proporcionar credenciales a un m√≥dulo de aplicaci√≥n, se utilizan salidas e entradas. Por ejemplo, un m√≥dulo de base de datos puede proporcionar una salida con las credenciales necesarias, y ese valor se pasa como entrada a un m√≥dulo de aplicaci√≥n para que lo utilice.

### Salidas y entradas

El uso de salidas (`outputs`) y entradas (`inputs`) en m√≥dulos permite que los datos se pasen entre ellos. Por ejemplo:

```hcl
output "db_password" {
  value = aws_secretsmanager_secret.db_password.secret_string
}

module "application" {
  source      = "./modules/application"
  db_password = module.database.db_password
}
```

En este ejemplo, el m√≥dulo de base de datos genera un `output` con la contrase√±a y este valor se pasa como `input` al m√≥dulo de la aplicaci√≥n.
# Infraestructura como C√≥digo (IaC) con Terraform

## Investigaci√≥n sobre c√≥mo organiza Terraform sus m√≥dulos

Terraform es una herramienta de infraestructura como c√≥digo que permite a los usuarios definir y aprovisionar infraestructura a trav√©s de archivos de configuraci√≥n. Terraform organiza su infraestructura en m√≥dulos, que son conjuntos de archivos de configuraci√≥n de Terraform que definen recursos relacionados que se pueden reutilizar.

Los m√≥dulos en Terraform ayudan a organizar y estructurar proyectos complejos de manera que se puedan reutilizar y mantener con facilidad. Un m√≥dulo en Terraform puede ser tan simple como un √∫nico archivo `.tf` o tan complejo como un conjunto de carpetas y archivos que estructuran el proyecto en bloques l√≥gicos.

### Terraform tiene dos tipos principales de m√≥dulos:

- **M√≥dulos ra√≠z:** Son los archivos `.tf` en el directorio principal de un proyecto. Este m√≥dulo se llama impl√≠citamente y se refiere a la infraestructura del proyecto.
- **M√≥dulos reutilizables:** Son m√≥dulos que pueden almacenarse en una carpeta separada y ser reutilizados en diferentes partes de la infraestructura.

## Propuesta de estructura de archivos y directorios para un proyecto con tres m√≥dulos: `network`, `database` y `application`

Para un proyecto que incluya tres m√≥dulos `network`, `database` y `application`, la estructura de archivos y directorios de Terraform podr√≠a ser la siguiente:

```bash
project/
‚îú‚îÄ‚îÄ main.tf                # Archivo principal que organiza los m√≥dulos y los recursos principales.
‚îú‚îÄ‚îÄ variables.tf           # Variables globales que se pueden reutilizar en todo el proyecto.
‚îú‚îÄ‚îÄ outputs.tf             # Variables de salida globales (por ejemplo, IP p√∫blica, nombre de la base de datos).
‚îú‚îÄ‚îÄ modules/
‚îÇ   ‚îú‚îÄ‚îÄ network/           # M√≥dulo para gestionar la red (VPC, subredes, etc.)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.tf        # Definici√≥n de recursos de red (subredes, VPC, etc.)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ variables.tf   # Variables espec√≠ficas del m√≥dulo de red.
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ outputs.tf     # Salidas del m√≥dulo de red (por ejemplo, CIDR de la VPC, direcciones IP).
‚îÇ   ‚îú‚îÄ‚îÄ database/          # M√≥dulo para gestionar la base de datos (RDS, configuraciones de acceso).
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.tf        # Definici√≥n de recursos de base de datos.
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ variables.tf   # Variables espec√≠ficas del m√≥dulo de base de datos.
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ outputs.tf     # Salidas del m√≥dulo de base de datos.
‚îÇ   ‚îî‚îÄ‚îÄ application/       # M√≥dulo para gestionar la aplicaci√≥n (EC2, aplicaciones, etc.).
‚îÇ       ‚îú‚îÄ‚îÄ main.tf        # Definici√≥n de recursos para la aplicaci√≥n (servidores, balanceadores).
‚îÇ       ‚îú‚îÄ‚îÄ variables.tf   # Variables espec√≠ficas del m√≥dulo de la aplicaci√≥n.
‚îÇ       ‚îú‚îÄ‚îÄ outputs.tf     # Salidas del m√≥dulo de la aplicaci√≥n.
```

### Justificaci√≥n de la jerarqu√≠a elegida

- **`main.tf`**: Organiza los m√≥dulos y puede llamar a los m√≥dulos `network`, `database` y `application`. Este archivo act√∫a como el punto de entrada principal para la configuraci√≥n de la infraestructura.
- **`variables.tf`**: Define las variables globales que se pueden utilizar en todo el proyecto. Al centralizar las variables, se facilita la reutilizaci√≥n y la flexibilidad en la infraestructura.
- **`outputs.tf`**: Define las salidas globales del proyecto, lo que permite acceder f√°cilmente a los recursos creados, como la direcci√≥n IP p√∫blica de la aplicaci√≥n.
- **`modules/`**: Cada m√≥dulo es independiente, lo que facilita su reutilizaci√≥n y mantenimiento. Los m√≥dulos est√°n organizados por su funci√≥n, de forma que cada uno contiene los archivos necesarios para gestionar un recurso espec√≠fico.

La modularizaci√≥n permite un enfoque m√°s organizado y escalable, facilitando la reutilizaci√≥n de la infraestructura y la colaboraci√≥n entre equipos.

---

# Contenerizaci√≥n y Despliegue de Aplicaciones Modernas

## Contenerizaci√≥n de una aplicaci√≥n con Docker

### ¬øQu√© son los contenedores?

Los contenedores son unidades de software que empaquetan una aplicaci√≥n y sus dependencias, como bibliotecas, archivos de configuraci√≥n y herramientas necesarias para ejecutar el software. A diferencia de las m√°quinas virtuales (VMs), que requieren un sistema operativo completo para funcionar, los contenedores comparten el mismo n√∫cleo del sistema operativo subyacente, lo que los hace mucho m√°s ligeros y r√°pidos de arrancar.

### Diferencia con m√°quinas virtuales (VMs):

- **M√°quinas virtuales (VMs):** Virtualizan un sistema operativo completo y requieren una cantidad significativa de recursos (memoria y CPU).
- **Contenedores:** Solo virtualizan el espacio de usuario y comparten el n√∫cleo del sistema operativo subyacente, lo que los hace m√°s ligeros y eficientes.

### Beneficios de los contenedores:

- **Aislamiento de procesos:** Los contenedores pueden ejecutarse de forma independiente sin interferir entre s√≠.
- **Ligereza:** No necesitan un sistema operativo completo y comparten recursos con el sistema host, optimizando el uso de recursos.

## Dockerfile

Un `Dockerfile` es un archivo de texto que contiene las instrucciones para construir una imagen de Docker. Estas instrucciones definen qu√© sistema operativo base usar, qu√© dependencias instalar, c√≥mo configurar la aplicaci√≥n y c√≥mo ejecutar el contenedor.

### Estructura b√°sica de un Dockerfile:

```dockerfile
# 1. Especificar la imagen base
FROM ubuntu:20.04

# 2. Instalar dependencias necesarias
RUN apt-get update && apt-get install -y python3 python3-pip

# 3. Copiar archivos locales al contenedor
COPY . /app

# 4. Establecer el directorio de trabajo
WORKDIR /app

# 5. Instalar dependencias de la aplicaci√≥n
RUN pip3 install -r requirements.txt

# 6. Comando para ejecutar la aplicaci√≥n
CMD ["python3", "app.py"]
```

### Imagen vs Contenedor

- **Imagen:** Es una plantilla inmutable que define lo que contiene un contenedor. Se usa para crear contenedores.
- **Contenedor:** Es una instancia en ejecuci√≥n de una imagen.

## Orquestaci√≥n con Kubernetes

### Introducci√≥n a Kubernetes

Kubernetes es una plataforma de orquestaci√≥n de contenedores que automatiza el despliegue, la escalabilidad y la gesti√≥n de aplicaciones en contenedores.

### Componentes principales de Kubernetes:

- **Pods:** Unidad m√°s peque√±a de despliegue en Kubernetes.
- **Servicios:** Exponen los Pods a una red interna o externa.
- **Implementaciones:** Aseguran que un n√∫mero deseado de r√©plicas de un Pod est√© en ejecuci√≥n.
- **Conjuntos de r√©plicas:** Mantienen un n√∫mero espec√≠fico de r√©plicas de un Pod.

## Manifiestos en YAML

Ejemplo b√°sico de un Deployment en Kubernetes:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
        - name: my-app-container
          image: my-app-image:v1
          ports:
            - containerPort: 80
```

### Estrategias de implementaci√≥n en Kubernetes:

- **Actualizaciones continuas:** Sin tiempo de inactividad.
- **Lanzamientos Canary:** Se prueba una nueva versi√≥n con un subconjunto de usuarios.
- **Implementaciones azul-verde:** Dos versiones coexisten y el tr√°fico se redirige a la nueva versi√≥n una vez lista.

## **Flujo Simple de Implementaci√≥n en Kubernetes**

Un flujo t√≠pico de implementaci√≥n de c√≥digo en un entorno basado en **Docker** y **Kubernetes** sigue estos pasos:

### **1. Desarrollador realiza un cambio en el c√≥digo**  
- El desarrollador modifica el c√≥digo en su entorno local y lo sube a un repositorio Git (por ejemplo, GitHub, GitLab o Bitbucket).
- Se crea un **pull request (PR)** y se revisan los cambios antes de fusionarlos a la rama principal.

### **2. Construcci√≥n de una nueva imagen Docker**  
- Un pipeline de **CI/CD (por ejemplo, GitHub Actions, GitLab CI/CD, Jenkins, ArgoCD)** detecta los cambios y ejecuta los siguientes pasos:
  - Descarga el c√≥digo actualizado.
  - Construye una nueva imagen Docker con el comando:
    ```sh
    docker build -t myapp:v2 .
    ```
  - Etiqueta la imagen y la sube a un **registro de contenedores** (Docker Hub, Amazon ECR, Google Container Registry, etc.):
    ```sh
    docker push myregistry/myapp:v2
    ```

### **3. Actualizaci√≥n del Deployment en Kubernetes**  
- Se actualiza el manifiesto de Kubernetes (`deployment.yaml`) con la nueva imagen:
  ```yaml
  apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: myapp
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: myapp
    template:
      metadata:
        labels:
          app: myapp
      spec:
        containers:
          - name: myapp
            image: myregistry/myapp:v2
            ports:
              - containerPort: 80
  ```
- Se aplica el cambio en Kubernetes:
  ```sh
  kubectl apply -f deployment.yaml
  ```
- Kubernetes realiza una **actualizaci√≥n continua (Rolling Update)**, reemplazando los pods con la versi√≥n antigua por nuevos pods con la nueva imagen.

### **4. Verificaci√≥n y monitoreo**  
- Se supervisa el despliegue para asegurarse de que los nuevos pods est√°n en funcionamiento:
  ```sh
  kubectl get pods
  ```
- Se revisan los logs para detectar posibles errores:
  ```sh
  kubectl logs -f myapp-pod-name
  ```
- Si algo falla, se puede hacer un rollback a la versi√≥n anterior:
  ```sh
  kubectl rollout undo deployment myapp
  ```

---

## **Ventajas de Kubernetes para Escalar en un Evento de Alto Tr√°fico**

### **1. Autoescalado basado en demanda**  
- Kubernetes permite **autoescalar** el n√∫mero de pods en funci√≥n del tr√°fico o el consumo de recursos.  
- Con el **Horizontal Pod Autoscaler (HPA)**, Kubernetes ajusta autom√°ticamente la cantidad de r√©plicas seg√∫n la carga:
  ```sh
  kubectl autoscale deployment myapp --cpu-percent=50 --min=3 --max=10
  ```
- As√≠, si el tr√°fico aumenta, Kubernetes crea m√°s instancias de la aplicaci√≥n para manejar las solicitudes sin intervenci√≥n manual.

### **2. Balanceo de carga**  
- Kubernetes distribuye las solicitudes entre los diferentes pods con un **Service de tipo LoadBalancer** o **Ingress Controller**, evitando la sobrecarga de un solo servidor.

### **3. Orquestaci√≥n eficiente de contenedores**  
- Kubernetes programa y reasigna contenedores en nodos disponibles, optimizando los recursos y asegurando alta disponibilidad.

### **4. Escalabilidad vertical y horizontal**  
- Si un evento de alto tr√°fico requiere m√°s capacidad, Kubernetes puede:
  - **Agregar m√°s r√©plicas de pods (escalado horizontal).**
  - **Aumentar los recursos de CPU/RAM asignados a los pods (escalado vertical).**

### **5. Recuperaci√≥n autom√°tica (Self-healing)**  
- Si un pod falla debido a la alta demanda, Kubernetes lo reinicia autom√°ticamente o lo reemplaza en otro nodo disponible.

### **6. Optimizaci√≥n de costos**  
- En un entorno en la nube, Kubernetes puede reducir costos escalando hacia arriba solo cuando es necesario y reduciendo recursos cuando el tr√°fico disminuye.

---

### **Ejemplo pr√°ctico**  
Durante el **Black Friday**, una tienda online experimenta un aumento en la demanda. Kubernetes:
1. **Escala autom√°ticamente** de 3 a 20 r√©plicas seg√∫n el consumo de CPU.
2. **Redirige el tr√°fico** entre los pods disponibles.
3. **Mantiene la disponibilidad** incluso si algunos nodos fallan.
4. **Reduce los recursos** despu√©s del evento para ahorrar costos.

‚úÖ **Resultado**: La aplicaci√≥n maneja el pico de tr√°fico sin interrupciones y sin intervenci√≥n manual. üöÄ
  # Integraci√≥n de Prometheus y Grafana con Kubernetes para monitoreo

Prometheus y Grafana son herramientas populares utilizadas para monitorear y visualizar m√©tricas de aplicaciones y sistemas. Su integraci√≥n con Kubernetes permite monitorear contenedores y clusters, proporcionando visibilidad completa del estado de la infraestructura.

## Prometheus

Prometheus es una herramienta de monitoreo de c√≥digo abierto dise√±ada para recopilar m√©tricas de aplicaciones y sistemas, almacenarlas de manera eficiente y proporcionar alertas en tiempo real. Su funcionamiento en un entorno Kubernetes incluye varios pasos clave:

### Scraping de m√©tricas
Prometheus se configura para recolectar m√©tricas de diferentes fuentes, como aplicaciones, bases de datos y otros servicios. En Kubernetes, Prometheus generalmente se implementa como un pod o deployment que usa un servicio de descubrimiento din√°mico para encontrar las direcciones de las aplicaciones y nodos.

### Kubernetes discovery
Prometheus utiliza la API de Kubernetes para descubrir din√°micamente los servicios y contenedores en el cl√∫ster. Esto incluye Pods, nodos y servicios, lo que le permite hacer scraping de m√©tricas sin intervenci√≥n manual.

### Recolecci√≥n de m√©tricas de contenedores
Prometheus recolecta m√©tricas de contenedores a trav√©s de los exportadores. Algunos ejemplos son:

- **cAdvisor**: para recolectar m√©tricas sobre los contenedores (uso de CPU, memoria, etc.).
- **Node Exporter**: para monitorear m√©tricas de los nodos, como uso de CPU, memoria y espacio en disco.
- **Kube-state-metrics**: para obtener m√©tricas del estado de los recursos de Kubernetes como Pods, Deployments, Services, etc.

### Alertas y reglas
Prometheus tambi√©n se puede configurar para generar alertas basadas en las m√©tricas que recolecta. Las alertas se pueden definir en un archivo de configuraci√≥n usando **PromQL** (Prometheus Query Language) y se integran con **Alertmanager** para la gesti√≥n de notificaciones.

## Grafana

Grafana es una plataforma de visualizaci√≥n de m√©tricas que se utiliza para crear paneles de control (dashboards) interactivos. Se integra con Prometheus para visualizar las m√©tricas recopiladas.

### Conexi√≥n con Prometheus
Grafana se configura para usar Prometheus como fuente de datos. Una vez configurado, Grafana puede consultar Prometheus utilizando PromQL y mostrar los resultados en gr√°ficos y tablas.

### Dashboards
Grafana permite crear dashboards personalizados que visualizan diferentes m√©tricas y alertas en tiempo real. Existen dashboards predefinidos disponibles en la **Grafana Dashboard Repository**, o puedes crear los tuyos propios.

### Alertas en Grafana
Grafana tambi√©n puede gestionar alertas basadas en las m√©tricas de Prometheus y enviar notificaciones a trav√©s de canales como Slack o correo electr√≥nico.

---

## Propuesta de m√©tricas y alertas m√≠nimas para una aplicaci√≥n web

Para una aplicaci√≥n web, el monitoreo debe centrarse en m√©tricas clave que permitan detectar problemas de rendimiento, disponibilidad y estabilidad.

### **M√©tricas m√≠nimas para monitorear**

#### **Latencia de peticiones**
- **M√©trica**: Latencia promedio de las solicitudes HTTP (en milisegundos).
- **PromQL**:
  ```promql
  http_request_duration_seconds_sum / http_request_duration_seconds_count
  ```

#### **Tasa de errores (Error Rate)**
- **M√©trica**: Tasa de respuestas con c√≥digo de error (4xx, 5xx).
- **PromQL**:
  ```promql
  sum(rate(http_requests_total{status=~"4..|5.."}[1m])) / sum(rate(http_requests_total[1m]))
  ```

#### **Uso de CPU**
- **M√©trica**: Porcentaje de uso de CPU de los contenedores de la aplicaci√≥n.
- **PromQL**:
  ```promql
  avg(rate(container_cpu_usage_seconds_total{container_name!="", pod_name=~"app-.*"}[5m])) by (pod_name)
  ```

#### **Uso de memoria**
- **M√©trica**: Memoria utilizada por los contenedores de la aplicaci√≥n.
- **PromQL**:
  ```promql
  avg(container_memory_usage_bytes{container_name!="", pod_name=~"app-.*"}) by (pod_name)
  ```

#### **Tasa de solicitudes**
- **M√©trica**: N√∫mero total de solicitudes HTTP recibidas por la aplicaci√≥n.
- **PromQL**:
  ```promql
  sum(rate(http_requests_total{method="GET", status="200"}[5m])) by (pod_name)
  ```

#### **Disponibilidad del servicio**
- **M√©trica**: Estado del pod (si est√° en estado "Running" o no).
- **PromQL**:
  ```promql
  kube_pod_status_phase{phase="Running"}
  ```

---

### **Alertas m√≠nimas para la aplicaci√≥n web**

#### **Alerta por alta latencia**
- **Condici√≥n**: Si la latencia promedio de las solicitudes HTTP excede un umbral (por ejemplo, 200 ms).
- **PromQL**:
  ```promql
  http_request_duration_seconds_sum / http_request_duration_seconds_count > 0.2
  ```

#### **Alerta por alta tasa de errores (4xx o 5xx)**
- **Condici√≥n**: Si la tasa de errores supera un umbral (por ejemplo, 5% de todas las solicitudes).
- **PromQL**:
  ```promql
  sum(rate(http_requests_total{status=~"4..|5.."}[1m])) / sum(rate(http_requests_total[1m])) > 0.05
  ```

#### **Alerta por uso elevado de CPU**
- **Condici√≥n**: Si el uso de CPU supera un umbral (por ejemplo, 90% durante 5 minutos).
- **PromQL**:
  ```promql
  avg(rate(container_cpu_usage_seconds_total{container_name!="", pod_name=~"app-.*"}[5m])) by (pod_name) > 0.9
  ```

#### **Alerta por uso elevado de memoria**
- **Condici√≥n**: Si el uso de memoria supera un umbral cr√≠tico (por ejemplo, 90% de la memoria disponible).
- **PromQL**:
  ```promql
  avg(container_memory_usage_bytes{container_name!="", pod_name=~"app-.*"}) by (pod_name) > 0.9 * container_spec_memory_limit_bytes
  ```

#### **Alerta por ca√≠da de un pod**
- **Condici√≥n**: Si un pod no est√° en estado "Running" (por ejemplo, si est√° en "CrashLoopBackOff").
- **PromQL**:
  ```promql
  kube_pod_status_phase{phase!="Running", pod_name=~"app-.*"}
  
 # Tarea Te√≥rica

## Diferencia entre Entrega Continua (*Continuous Delivery*) y Despliegue Continuo (*Continuous Deployment*)

### **1. Entrega Continua (*Continuous Delivery*)**
La **entrega continua** es una pr√°ctica de desarrollo en la que los cambios en el c√≥digo son autom√°ticamente probados y preparados para su lanzamiento a producci√≥n. Sin embargo, el despliegue en producci√≥n **no es autom√°tico**; requiere una aprobaci√≥n manual antes de que la nueva versi√≥n del software sea publicada.

**Caracter√≠sticas principales:**
- Se garantiza que el c√≥digo siempre est√© en un estado desplegable.
- Se automatizan las pruebas y la generaci√≥n de artefactos listos para producci√≥n.
- El equipo puede decidir cu√°ndo y c√≥mo hacer el despliegue en producci√≥n.

üìå **Ejemplo:** Un equipo de desarrollo configura un pipeline CI/CD que ejecuta pruebas y construye una nueva versi√≥n del software, pero un ingeniero de DevOps debe aprobar manualmente el despliegue en producci√≥n.

---

### **2. Despliegue Continuo (*Continuous Deployment*)**
El **despliegue continuo** lleva la entrega continua un paso m√°s all√° al automatizar completamente el proceso de despliegue. En este caso, cada cambio en el c√≥digo que pasa las pruebas **se despliega autom√°ticamente en producci√≥n**, sin intervenci√≥n manual.

**Caracter√≠sticas principales:**
- Requiere una estrategia robusta de pruebas autom√°ticas para minimizar riesgos.
- Reduce el tiempo de entrega de nuevas funcionalidades a los usuarios finales.
- Aumenta la frecuencia de despliegues en producci√≥n.

üìå **Ejemplo:** Cada vez que un desarrollador fusiona (*merge*) cambios en la rama principal, un pipeline automatizado ejecuta pruebas, genera una nueva versi√≥n y la despliega directamente en producci√≥n sin intervenci√≥n manual.

---

## Importancia de las Pruebas Autom√°ticas en el Pipeline

Implementar pruebas autom√°ticas dentro del pipeline de CI/CD es fundamental para garantizar la calidad del software y evitar errores en producci√≥n. Existen varios tipos de pruebas que deben incluirse:

### **1. Pruebas Unitarias**
- **Objetivo**: Validar que cada unidad de c√≥digo (*funci√≥n, m√≥dulo o clase*) funciona correctamente de manera aislada.
- **Beneficio**: Detectar errores en etapas tempranas y garantizar que las funciones individuales operen seg√∫n lo esperado.
- **Ejemplo**: Probar que una funci√≥n que suma dos n√∫meros devuelva el resultado correcto.

### **2. Pruebas de Integraci√≥n**
- **Objetivo**: Evaluar c√≥mo interact√∫an entre s√≠ los diferentes m√≥dulos o servicios de la aplicaci√≥n.
- **Beneficio**: Detectar fallos en la comunicaci√≥n entre componentes y evitar problemas de integraci√≥n antes del despliegue.
- **Ejemplo**: Verificar que el backend pueda comunicarse correctamente con la base de datos.

### **3. Pruebas de Seguridad**
- **Objetivo**: Identificar vulnerabilidades en el c√≥digo antes de que lleguen a producci√≥n.
- **Beneficio**: Prevenir ataques como inyecci√≥n SQL, XSS (*Cross-Site Scripting*), fugas de datos o accesos no autorizados.
- **Ejemplo**: Ejecutar escaneos de seguridad automatizados con herramientas como OWASP ZAP o SonarQube.

üìå **Conclusi√≥n**: Implementar pruebas autom√°ticas en el pipeline **reduce riesgos, mejora la estabilidad del software y acelera los tiempos de entrega** en entornos de entrega y despliegue continuo.

