## 1. DefiniciÃ³n de IaC y su cambio de paradigma frente a la configuraciÃ³n manual

Infraestructura como CÃ³digo (IaC) es un enfoque que permite gestionar la infraestructura usando archivos de configuraciÃ³n en vez de realizar configuraciones manuales a travÃ©s de interfaces grÃ¡ficas o herramientas de administraciÃ³n tradicionales. Este enfoque describe el estado deseado de la infraestructura utilizando un lenguaje declarativo o imperativo, lo que facilita la creaciÃ³n, modificaciÃ³n y administraciÃ³n de recursos de manera automÃ¡tica.

### Cambio de paradigma

La diferencia principal entre IaC y la configuraciÃ³n manual es que en IaC la infraestructura se gestiona como cÃ³digo, permitiendo la automatizaciÃ³n completa del ciclo de vida de los recursos. Esto reduce significativamente los errores humanos, ya que las configuraciones y cambios se pueden revisar, versionar y auditar a travÃ©s de herramientas de control de versiones como Git.

### Beneficios de IaC

- **Consistencia en la configuraciÃ³n**: La infraestructura definida como cÃ³digo puede aplicarse de manera consistente en diferentes entornos (desarrollo, prueba, producciÃ³n) sin la posibilidad de diferencias manuales.
- **Control de versiones**: Los archivos de configuraciÃ³n son versionados, lo que permite hacer un seguimiento de los cambios, revertir configuraciones errÃ³neas y mantener un historial completo de la infraestructura.
- **AutomatizaciÃ³n**: La infraestructura se aprovisiona, configura y gestiona automÃ¡ticamente sin intervenciÃ³n manual. Esto optimiza el tiempo y esfuerzo de los equipos de TI.
- **ReducciÃ³n de errores humanos**: Al evitar configuraciones manuales, el riesgo de cometer errores en el proceso de configuraciÃ³n se reduce considerablemente, ya que todo el proceso estÃ¡ automatizado y auditado.



## 2. Herramientas populares para IaC

Algunas de las herramientas mÃ¡s populares para implementar IaC son:

- **Terraform**: Utilizada para  mÃºltiples proveedores de nube como AWS, Azure y Google Cloud. Utiliza el HashiCorp Configuration Language (HCL) para definir y gestionar la infraestructura.
- **Ansible**: Ansible npermite definir la infraestructura como cÃ³digo. Utiliza YAML para las describir tareas.
- **Pulumi**: Permite escribir IaC utilizando lenguajes de programaciÃ³n modernos como JavaScript, TypeScript, Python y Go.
- **AWS CloudFormation**: EspecÃ­fica para AWS, permite definir recursos de infraestructura en la nube utilizando archivos en JSON o YAML.



##  Buenas prÃ¡cticas en la escritura de IaC

- **Nombres claros de recursos**: Utilizar nombres descriptivos y consistentes para los recursos ayuda a identificar rÃ¡pidamente su propÃ³sito y facilita la gestiÃ³n en entornos grandes.
- **Uso de variables**: Las variables permiten reutilizar configuraciones de manera eficiente y hacer que los recursos sean mÃ¡s dinÃ¡micos y personalizables segÃºn el entorno.
- **ModularizaciÃ³n del cÃ³digo**: Es recomendable dividir la infraestructura en mÃ³dulos que se puedan reutilizar en diferentes proyectos o entornos. Por ejemplo, un mÃ³dulo para redes, otro para bases de datos y otro para aplicaciones.
- **Uso de repositorios de control de versiones (Git)**: Mantener el cÃ³digo de la infraestructura en un repositorio Git permite un control completo sobre los cambios, ademÃ¡s de colaborar y hacer auditorÃ­a sobre las configuraciones.

---

## 3. Patrones para mÃ³dulos en IaC

### ModularizaciÃ³n

Ayuda a la reutiliacion y la gestiÃ³n. Por ejemplo, un mÃ³dulo para configurar redes, otro para definir bases de datos y otro para gestionar servidores de aplicaciones.Los modulos pueden ser independientes y ggestionados de diferente manera, permitiendo su reutilizaciÃ³n en diferentes proyectos.

### Estructura

Una estructura de mÃ³dulos tÃ­pica en IaC podrÃ­a organizarse de la siguiente manera:

```
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ network/
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”œâ”€â”€ variables.tf
â”‚   â”‚   â””â”€â”€ outputs.tf
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”œâ”€â”€ variables.tf
â”‚   â”‚   â””â”€â”€ outputs.tf
â”‚   â””â”€â”€ application/
â”‚       â”œâ”€â”€ main.tf
â”‚       â”œâ”€â”€ variables.tf
â”‚       â””â”€â”€ outputs.tf
â”œâ”€â”€main.tf
â”œâ”€â”€ variables.tf
â””â”€â”€ outputs.tf
```

AquÃ­, cada mÃ³dulo tiene su propio conjunto de archivos que describen los recursos y las configuraciones, y luego los mÃ³dulos se llaman en el archivo `main.tf` del proyecto principal.

---

## 4. Patrones para dependencias en IaC

### GestiÃ³n de dependencias

Para enlazar mÃ³dulos que dependen entre sÃ­, como un mÃ³dulo de base de datos que debe proporcionar credenciales a un mÃ³dulo de aplicaciÃ³n, se utilizan salidas e entradas. Por ejemplo, un mÃ³dulo de base de datos puede proporcionar una salida con las credenciales necesarias, y ese valor se pasa como entrada a un mÃ³dulo de aplicaciÃ³n para que lo utilice.

### Salidas y entradas

El uso de salidas (`outputs`) y entradas (`inputs`) en mÃ³dulos permite que los datos se pasen entre ellos. Por ejemplo:

```hcl
output "db_password" {
  value = aws_secretsmanager_secret.db_password.secret_string
}

module "application" {
  source      = "./modules/application"
  db_password = module.database.db_password
}
```

En este ejemplo, el mÃ³dulo de base de datos genera un `output` con la contraseÃ±a y este valor se pasa como `input` al mÃ³dulo de la aplicaciÃ³n.



# Tarea teorica 1
## Terraform 

Terraform es una herramienta que permite a los usuarios gestionar infraestructura de un proyecto mediante archivos de configuraciÃ³n. Para organizar mejor los proyectos, Terraform usa mÃ³dulos, los cuales agrupan
archivos de configuraciÃ³n relacionados para facilitar su reutilizaciÃ³n y mantenimiento.
Un modulo consiste de una colecciÃ³n de archivos .tf y/o .tf.json que se mantienen juntas en un directorio.
Toda configuraciÃ³n de Terraform tiene al menos un mÃ³dulo, cono cido como el modulo raÃ­z que consiste en los recursos definidos en los archivos .tf en el directorio de trabajo principal 
-  **main.tf**:  Define los recursos principales del mÃ³dulo.
-  **variables.tf**: Contiene los parÃ¡metros de entrada
-  **outputs.tf**: Define las salidas del mÃ³dulo
-  **providers.tf**: (opcional): Declara los proveedores de nube o infraestructura usados.
-  **terraform.tfvars**: (opcional): Permite definir valores por defecto para las variables. 

project-terraform/
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ network/
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”œâ”€â”€ variables.tf
â”‚   â”‚   â”œâ”€â”€ outputs.tf
â”‚   â”‚   â”œâ”€â”€ provider.tf
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”œâ”€â”€ variables.tf
â”‚   â”‚   â”œâ”€â”€ outputs.tf
â”‚   â”‚   â”œâ”€â”€ provider.tf
â”‚   â”œâ”€â”€ application/
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”œâ”€â”€ variables.tf
â”‚   â”‚   â”œâ”€â”€ outputs.tf
â”‚   â”‚   â”œâ”€â”€ provider.tf
â”œâ”€â”€ environments/
â”‚   â”œâ”€â”€ dev/
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”œâ”€â”€ terraform.tfvars
â”‚   â”œâ”€â”€ prod/
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”œâ”€â”€ terraform.tfvars
â”œâ”€â”€ main.tf
â”œâ”€â”€ variables.tf
â”œâ”€â”€ outputs.tf
â”œâ”€â”€ provider.tf
â”œâ”€â”€ terraform.tfvars
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
 

### Â¿QuÃ© son los contenedores?

Los contenedores son unidades de software que empaquetan una aplicaciÃ³n y sus dependencias, como bibliotecas, archivos de configuraciÃ³n y herramientas necesarias para ejecutar el software. A diferencia de las mÃ¡quinas virtuales (VMs), que requieren un sistema operativo completo para funcionar, los contenedores comparten el mismo nÃºcleo del sistema operativo subyacente, lo que los hace mucho mÃ¡s ligeros y rÃ¡pidos de arrancar.

### Diferencia con mÃ¡quinas virtuales (VMs):

- **MÃ¡quinas virtuales (VMs):** Virtualizan un sistema operativo completo y requieren una cantidad significativa de recursos (memoria y CPU).
- **Contenedores:** Solo virtualizan el espacio de usuario y comparten el nÃºcleo del sistema operativo subyacente, lo que los hace mÃ¡s ligeros y eficientes.

## Dockerfile

Un `Dockerfile` es un archivo de texto que contiene las instrucciones para construir una imagen de Docker. Estas instrucciones definen quÃ© sistema operativo base usar, quÃ© dependencias instalar, cÃ³mo configurar la aplicaciÃ³n y cÃ³mo ejecutar el contenedor.

### Estructura bÃ¡sica de un Dockerfile:

```dockerfile
# 1. Especificar la imagen base
FROM ubuntu:20.04

# 2. Instalar dependencias necesarias
RUN apt-get update && apt-get install -y python3 python3-pip

# 3. Copiar archivos locales al contenedor
COPY . /app

# 4. Establecer el directorio de trabajo
WORKDIR /app

# 5. Instalar dependencias de la aplicaciÃ³n
RUN pip3 install -r requirements.txt

# 6. Comando para ejecutar la aplicaciÃ³n
CMD ["python3", "app.py"]
```

### Imagen vs Contenedor

- **Imagen:** Es una plantilla inmutable que define lo que contiene un contenedor. Se usa para crear contenedores.
- **Contenedor:** Es una instancia en ejecuciÃ³n de una imagen.

## OrquestaciÃ³n con Kubernetes

### IntroducciÃ³n a Kubernetes

### Componentes principales de Kubernetes:

- **Pods:** Unidad mÃ¡s pequeÃ±a de despliegue en Kubernetes.
- **Servicios:** Exponen los Pods a una red interna o externa.
- **Implementaciones:** Aseguran que un nÃºmero deseado de rÃ©plicas de un Pod estÃ© en ejecuciÃ³n.
- **Conjuntos de rÃ©plicas:** Mantienen un nÃºmero especÃ­fico de rÃ©plicas de un Pod.

## Manifiestos en YAML

Ejemplo bÃ¡sico de un Deployment en Kubernetes:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
        - name: my-app-container
          image: my-app-image:v1
          ports:
            - containerPort: 80
```
### Docker y Kubernetes se integran en pipelines de despliegue continuo (CD) para automatizar la creaciÃ³n, configuraciÃ³n, escalado, y gestiÃ³n de aplicaciones. 
 
# Tarea teorica 2
-**El desarrollador sube el cÃ³digo a GitHub**

-**Jenkins detecta el commit utilizando un webhook**

-**La imagen es construida y enviada al Docker Hub despuÃ©s de las pruebas**

-**Jenkins despliega la aplicaciÃ³n en el clÃºster de Kubernetes**

### Estrategias de implementaciÃ³n en Kubernetes:


## **Ventajas de Kubernetes para Escalar en un Evento de Alto TrÃ¡fico**
Kubernetes posee una caracterÃ­stica importante llamada autoescalado. Este permite que las apicaciones se ajusten automÃ¡ticamente a los cambios den la demanda eficientemente. Para esto, se emplea el escalado horizontal de pods (HPA). Este es un mecanismo que ajusta  automÃ¡ticamente la cantidad de copias de los Pods en funciÃ³n al uso de la CPU u otras mÃ©tricas.
Esto es Ãºtil ya que maneja picos de trÃ¡fico sin que la aplicaciÃ³n caiga, evita problemas de hardware distribuyendo la carga y tambiÃ©n se adapta a las interrupciones de red asegurando que la aplicaciÃ³n siempre
estÃ© disponible.

### **Ejemplo prÃ¡ctico**  
Durante el **Black Friday**, una tienda online experimenta un aumento en la demanda. Kubernetes:
1. **Escala automÃ¡ticamente** de 3 a 20 rÃ©plicas segÃºn el consumo de CPU.
2. **Redirige el trÃ¡fico** entre los pods disponibles.
3. **Mantiene la disponibilidad** incluso si algunos nodos fallan.
4. **Reduce los recursos** despuÃ©s del evento para ahorrar costos.

âœ… **Resultado**: La aplicaciÃ³n maneja el pico de trÃ¡fico sin interrupciones y sin intervenciÃ³n manual. ğŸš€
  # Tarea teorica 3
  ## INTEGRACION DE PROMETHEUS Y GRAFANA CON KUBERNETES PARA EL MONITOREO DE CONTENEDORES Y CLUSTERES
Prometheus es un sistema de monitoreo y alerta de cÃ³digo abierto. Se integra con Kubernetes para extraer datos sobre el rendimiento de los nodos, pods y contenedores. Utiliza lo que se conoce como pull para consultar periodicamente las metricas de los servicios mediante su lenguaje PromQL. Grafana se utiliza para representar grÃ¡ficamente las mÃ©tricas recolectadas por Prometheus. Necesitamos un servidor de 1. Grafana, corriendo 
1. **Necesitamos un servidor de  Grafana, corriendo**
2. **Necesitamos que en el mismo servidor donde se encuentre
Grafana haya un servidor de Prometheus corriendo como
servicio de Linux**
3. **Necesitamos que haya un servidor Prometheus en cada uno de los clusters de Kubernetes**

## SET DE METRICAS Y ALERTAS MÃNIMAS PARA UNA APLICACION WEB

Para una aplicaciÃ³n web, el monitoreo debe centrarse en mÃ©tricas clave que permitan detectar problemas de rendimiento, disponibilidad y estabilidad.

### **MÃ©tricas mÃ­nimas para monitorear**

#### **Latencia de peticiones**
- Medirlas en ms y establecer una alerta en el caso de se supere N ms en un intervalo determinado de tiempo.

#### **Uso de CPU**
 - El porcentaje de CPU utilizado en cada nodo o pod y establecer una alerta si el uso supera cierto porcentaje.

#### **Uso de memoria**
 - Medir cuanta memoria se usa respecto a la memoria que no se usa y establecer una alerta en el caso de  que se use mas de la que no se use.

#### **Tiempo de respuesta de la base de datos**
- Tiempo de respuesta en consultas muy importantes y establecer una alerta en el caso de que se supere el umbral de tiempo.

 # Tarea TeÃ³rica 4

## Diferencia entre Entrega Continua (*Continuous Delivery*) y Despliegue Continuo (*Continuous Deployment*)
La entrega continua (CD) cierra el ciclo mediante la automatizaciÃ³n de aspectos de la entrega de  software. A medida que se abordan los comentarios y se implementan correcciones, estos cambios  se cargan automÃ¡ticamente hasta que el equipo tome la decisiÃ³n de enviar la aplicaciÃ³n a producciÃ³n. La CD da lugar a un producto que se puede desplegar, pero depende de la autorizaciÃ³n 
humana para implantarlo, lo que permite a los equipos decidir quÃ© se debe lanzar y cuÃ¡ndo. Los desarrolladores pueden seguir perfeccionando la aplicaciÃ³n antes de entregarla al usuario final. El despliegue continuo es similar a la entrega continua. La principal diferencia con el despliegue continuo es que, en lugar de requerir una autorizaciÃ³n humana para lanzar un producto, el despliegue continuo envÃ­a cada cambio de forma automatizada, que luego se envÃ­a inmediatamente a producciÃ³n. No se espera un ciclo de aprobaciÃ³n manual, lo que significa que el cÃ³digo en sÃ­ mismo debe haberse probado lo suficiente antes de pasar a producciÃ³n. 

## Â¿POR QUÃ‰ ES IMPORTANTE IMPLEMENTAR PRUEBAS AUTOMÃTICAS (UNITARIAS, DE INTEGRACIÃ“N, DE SEGURIDAD) DENTRO DEL PIPELINE?

Porque aumentan la confiabilidad, consistencia y efciencia tanto del equipo como del producto final. Ayuda a ahorrar tiempo para que el equipo pueda centrarse en otras tareas. AdemÃ¡s, reduce la
posibilidad de que ocurran errores humana. La automatizacion de pruebas tambien ofrece flexibilidad, ya que los equipos de desarrollo puede reutilizar sus scripts de prueba para cualquier conjunto de pruebas relacionado.

